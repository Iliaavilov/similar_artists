{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Задача**\n",
    "\n",
    "Необходимо построить векторное представление музыкантов так, чтобы наиболее похожие музыка оказались в пространстве признаков как можно ближе друг к другу\n",
    "\n",
    "**Имеющиеся данные**\n",
    "1. Данные о пользователях\n",
    "2. Данные о музыкантах\n",
    "3. Данные о музыкальных композициях\n",
    "4. Данные о альбомах\n",
    "5. Данные о плейлистах пользователей\n",
    "\n",
    "**Выдвижение гипотезы**\n",
    "\n",
    "Т.к. в нашем датасете нет информации о реальной \"схожести\" исполнителей, то для того, чтобы искать эту \"схожесть\" необходимо поставить гипотезу.\n",
    "\n",
    "Гипотеза - пользователи в общей своей массе слушают похожих друг на друга исполнителей.\\\n",
    "Придерживаясь данной гипотезы мы можем перейти к задаче рекомендации похожих исполнителей пользователям\n",
    "\n",
    "**Способ решения задачи**\n",
    "\n",
    "Задачу поиска похожих исполнителей можно свести к задаче создания content-based рекомендательной системы\\\n",
    "Будем рекомендовать пользователю исполнителей, похожих на тех исполнителей, которых пользователь уже послушал\n",
    "\n",
    "**Оценка работы моделей**\n",
    "\n",
    "В нашем датасете отсутствует информация о том, какую оценку пользователь поставил треку, у нас имеются лишь данные о том, какие треки пользователь прослушал.\n",
    "\n",
    "Таким образом, у нас имеется implicit feedback, но не explicit feedback.\n",
    "\n",
    "То есть, если пользователь прослушал исполнителя i, но не прослушал исполнителя j, то это не значит, что ему нравится исполнитель i и не нравится исполнитель j, вполне возможно, что пользователь просто не знает про существование исполнителя j.\\\n",
    "Поэтому нам не подходят такие метрики оценивания как MAE, RMSE(например предсказывать, сколько раз пользователь будет слушать треки исполнителя i), которые часто используются в explicit feedback моделях для предсказания оценки, потому что у нас банально нет оценок, а также нет адекватной альтернативы, которую можно использовать в качестве оценки. Можно было бы использовать использовать в качестве target variable, например, время прослушивания треков артиста, или количество прослушиваний треков артиста пользвоателем, но в таком случае точность для каждого пользователя будет сильно зависеть от того, как часто пользователь слушает треки (например, для пользователя, часто прослушивающего треки, будет выгодно предсказывать большее количество треков/времени их прослушивания), в то время как пользователю, редко слушающему музыку, выгодно предсказать, что он вовсе ничего не прослушает. Однако, такие результаты не будут отражать реальную точность результатов\n",
    "\n",
    "Вместо этого я предлагаю использовать метрики, основанные на ранжировании музыкантов по \"вероятности\" того, что пользователь прослушает треки данного исполнителя. При этом измерять точность модели я буду на основании того, на каком месте в ранжированном списке исполнителей находятся исполнители, которых пользователь в действительности послушал. Такой способ оценки позволит оценить релевантность рекомендаций вне зависимости от того, как много и как часто пользователь слушает музыку. Чем \"ближе\" исполнители, которых слушает пользователь, к топу ранжированного списка, тем релевантнее рекомендация.\n",
    "\n",
    "**Алгоритм решения задачи**\n",
    "1. Построить векторное представление исполнителей\n",
    "2. Посчитать расстояние между всеми исполнителями.\n",
    "3. Выбрать информацию о расстоянии между исполнителями, которых прослушал пользователь, и всеми остальными исполнителями\n",
    "4. Для всех исполнителей посчитать среднее расстояние от них до исполнителей, которых уже послушал пользователь\n",
    "5. Отранжировать исполнителей в порядке возрастания среднего расстояния до уже прослушанных исполнителей\n",
    "6. Посчитать метрику работы модели - среднее относительное место(кванитиль) исполнителей, которых прослушал пользователь, в ранжированном списке исполнителей. Следовательно, чем меньшее среднее место (квантиль) - тем лучше модель рекомендует пользователю исполнителей\n",
    "\n",
    "При этом вместо абсолютного среднего места будет использоваться именно относительное (то есть среднее место разделить на длину ранжированного списка), т.к. при использовании разных данных(о плейлистах/сессиях/всех прослушиваниях) длины ранжированного списка получались разные (потому что в разных датасетах есть информация о разных исполнителях, не о всех сразу).\n",
    "\n",
    "\n",
    "\n",
    "При этом метрики расстояния я буду использовать разные, а не только евклидову метрику расстояния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Список исполнителей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. MBID\n",
    "2. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data = pd.read_csv('entities\\\\persons.idomaar', sep = '\\t', names = ['person', 'person_id', 'timestamp', 'json_data', 'delete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person_data['json_data'] = person_data['json_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data['MBID'] = person_data['json_data'].apply(lambda x: x['MBID'])\n",
    "person_data['artist_name'] = person_data['json_data'].apply(lambda x: x['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(person_data['person'].unique())\n",
    "print(person_data['timestamp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data = person_data.drop(['person', 'timestamp', 'json_data', 'delete'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data.to_csv('persons.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Список треков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Длительность трека\n",
    "2. Сколько раз прослушали трек\n",
    "3. MBID\n",
    "4. Название\n",
    "5. Артист\n",
    "6. Альбом\n",
    "7. Тэги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data = pd.read_csv('entities\\\\tracks.idomaar', sep = '\\t', names = ['track', 'track_id',  'timestamp', 'json_data', 'linked_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data['json_data'] = tracks_data['json_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data['duration'] = tracks_data['json_data'].apply(lambda x: x['duration'])\n",
    "tracks_data['playcount'] = tracks_data['json_data'].apply(lambda x: x['playcount'])\n",
    "tracks_data['MBID'] = tracks_data['json_data'].apply(lambda x: x['MBID'])\n",
    "tracks_data['name'] = tracks_data['json_data'].apply(lambda x: x['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data['linked_data'] = tracks_data['linked_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data['artist_id'] = tracks_data['linked_data'].apply(lambda x: x['artists'][0]['id'])\n",
    "tracks_data['albums'] = tracks_data['linked_data'].apply(lambda x: x['albums'])\n",
    "tracks_data['tags'] = tracks_data['linked_data'].apply(lambda x: x['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data = tracks_data.drop(['track', 'timestamp', 'json_data', 'linked_data'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracks_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_data.to_csv('tracks.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Плейлисты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data = pd.read_csv('entities\\\\playlist.idomaar', sep = '\\t', names = ['playlist', 'playlist_id', 'timestamp', 'json_data', 'playlist_tracks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data['json_data'] = playlist_data['json_data'].apply(lambda x: re.sub('\\\"Title\\\":.*?,(?=\\\"numtracks\\\")', '', x))\n",
    "playlist_data['json_data'] = playlist_data['json_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playlist_data['numtracks'] = playlist_data['json_data'].apply(lambda x: x['numtracks'])\n",
    "playlist_data['duration'] = playlist_data['json_data'].apply(lambda x: x['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data['playlist_tracks'] = playlist_data['playlist_tracks'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data['user_id'] = playlist_data['playlist_tracks'].apply(lambda x: x['subjects'][0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data['playlist_tracks'] = playlist_data['playlist_tracks'].apply(lambda x: x['objects'])\n",
    "playlist_data = playlist_data[playlist_data['playlist_tracks'].astype(str) != '[[]]'].reset_index(drop = True)\n",
    "playlist_data = playlist_data[playlist_data['numtracks']!= 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playlist_data['playlist_tracks'] = playlist_data['playlist_tracks'].apply(lambda x: list(map(lambda y: y['id'], x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data = playlist_data.explode('playlist_tracks')\n",
    "playlist_data = playlist_data.rename(columns = {'playlist_tracks' : 'track_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data = playlist_data.drop(['playlist', 'json_data'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "playlist_data.to_csv('playlists.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Список прослушиваний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Play time\n",
    "2. Пользователь\n",
    "3. Трек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('relations\\\\events.idomaar', sep = '\\t', names = ['event_type', 'event_id',  'timestamp', 'playtime', 'json_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data['json_data'] = event_data['json_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data['user_id'] = event_data['json_data'].apply(lambda x: x['subjects'][0]['id'])\n",
    "event_data['track_id'] = event_data['json_data'].apply(lambda x: x['objects'][0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_data['playtime'] = event_data['playtime'].apply(lambda x: json.loads(x)['playtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = event_data.drop(['event_type', 'json_data'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data.to_csv('events.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Список сессий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = pd.read_csv('relations\\\\sessions.idomaar', sep = '\\t', names = ['event.session', 'session_id', 'timestamp', 'json_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = pd.concat([session_data, session_data['json_data'].str.split(' ', expand = True).rename(columns = {0 : 'session_data', 1: 'session_tracks'})], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_data['session_data'] = session_data['session_data'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_data['numtracks'] = session_data['session_data'].apply(lambda x: x['numtracks'])\n",
    "session_data['playtime'] = session_data['session_data'].apply(lambda x: x['playtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data['session_tracks'] = session_data['session_tracks'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data['user_id'] = session_data['session_tracks'].apply(lambda x: x['subjects'][0]['id'])\n",
    "session_data['session_tracks'] = session_data['session_tracks'].apply(lambda x: x['objects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = session_data.explode('session_tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data['action_type'] = session_data['session_tracks'].apply(lambda x: x['action'])\n",
    "session_data['track_id'] = session_data['session_tracks'].apply(lambda x: x['id'])\n",
    "session_data['playstart'] = session_data['session_tracks'].apply(lambda x: x['playstart'])\n",
    "session_data['playtime'] = session_data['session_tracks'].apply(lambda x: x['playtime'])\n",
    "session_data['playratio'] = session_data['session_tracks'].apply(lambda x: x['playratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = session_data.drop(['event.session', 'json_data', 'session_data', 'session_tracks'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data.to_csv('sessions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обзор и чистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data = pd.read_csv('tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим данные на наличие дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicated_rows = track_data.duplicated(['track_id', 'artist_id'])\n",
    "duplicated_rows = duplicated_rows[duplicated_rows == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicated_tracks = track_data.loc[duplicated_rows.index, :]['track_id'].values\n",
    "duplicated_artists = track_data.loc[duplicated_rows.index, :]['artist_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(duplicated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Таким образом, всего в данных о треках есть 1155824 дубликатов. Рассмотрим их подробнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data[(track_data['track_id'].isin(duplicated_tracks)) & (track_data['artist_id'].isin(duplicated_artists))].sort_values('artist_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Удалим все дубликаты в парах (track_id - artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data = track_data[(track_data['track_id'].isin(duplicated_tracks) == False) & (track_data['artist_id'].isin(duplicated_artists) == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data = track_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Теперь рассмотрим повторяющиеся треки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicated_tracks = track_data.duplicated('track_id')\n",
    "duplicated_tracks = duplicated_tracks[duplicated_tracks == True]\n",
    "duplicated_tracks = track_data.loc[duplicated_tracks.index, :]['track_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicated_rows = track_data[track_data['track_id'].isin(duplicated_tracks)].sort_values('track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Подробнее рассмотрим данных исполнителей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data = pd.read_csv('persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data[person_data['person_id'].isin(duplicated_rows['artist_id'].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "На самом деле исполнители с разными id одни и те же исполнители, у которых просто немного отличаются названия групп/имена исполнителей. Adventures+Of+Stevie+V тоже самое, что и The+Adventures+Of+Stevie+V. Объединим в нашем датасете этих исполнителей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data['artist_id'] = track_data['artist_id'].replace({468413: 11173, 168789: 168790, 416502: 416503})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим частоту встречаемости названий треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_data['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Треки с названием ZZ+Top/_/She+Loves+My+Automobile  встречаются слишком часто. Рассмотрим их подробнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data[track_data['name'] == 'ZZ+Top/_/She+Loves+My+Automobile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим несколько исполнителей из датасета выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data[person_data['person_id'].isin([508184, 224835, 440240, 595138, 595139])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Исполнители действительно разные, но названия треков одинаковые. Скорее всего это просто ошибочные названия треков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Удалим появившиесся дубликаты в паррах track_id - artist_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data = track_data.drop_duplicates(['track_id', 'artist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим пропущенные значения в колонке duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data[(track_data['duration'].isna()) | (track_data['duration'] == -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В большинстве треков пропущены данные о длительности, так что я не буду использовать эту переменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Сохраним отфильтрованный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data.to_csv('tracks_modified.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим информацию о дате прослушивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dates = event_data['timestamp'].apply(lambda x: datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10, 10))\n",
    "_ = plt.title('Распределение количества прослушанных треков во времени')\n",
    "_ = dates.hist(bins = 200, grid = False)\n",
    "_ = plt.xlabel('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Распределение равномерное, с выбросом ближе к концу выборки. Будем учитывать это при оценке работы моделей (будем стараться избегать конца выборки, т.к. там данные не следуют общей тенденции)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим информацию о времени прослушивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10,10))\n",
    "_ = plt.title('99 квантиль распределения длительности трека')\n",
    "_ = sns.distplot(event_data[event_data['playtime']<np.quantile(event_data['playtime'], 0.99)]['playtime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Распределение прослушивания треков выглядит как нормальное, однако присутствует длинный хвост справа\\\n",
    "Также в левой части распределения наблюдается выброс. Рассмотрим его подробнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data['playtime'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "У большого количества треков длительность прослушивания 0 или -1. Удалим наблюдения, в которых длительность прослушивания менее 10 секунд, т.к. можно предположить, что польователь просто скипал эти треки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = event_data[event_data['playtime']>=10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Сохраним отфильтрованные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data.to_csv('events_modified.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = pd.read_csv('sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рассмотрим тип действия во время сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data['action_type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_data[session_data['action_type'] == 'skip']['playtime'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Удалим из сессий те треки, которые пользователь скипнул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = session_data[session_data['action_type'] != 'skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data[session_data['action_type'].isna()]['playtime'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Если нет информации о типе действия, то нет и информации о длителньости прослушивания трека. Также удалим такие наблюдения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data = session_data[session_data['action_type'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(session_data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Распределение времени сессий такое же, как и у времени прослушивания треков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Сохраним полученный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session_data.to_csv('sessions_modified.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Валидация моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Общий алгоритм оценки работы моделей:\n",
    "\n",
    "1. Разбить данные по времени на 2 подвыборки - train и test (длительность test period = 60 дней, начало тестового периода: 07/10/2014)\n",
    "2. Выбрать тех пользователей, у которых есть оценка в обоих подвыборках\n",
    "3. Рандомно выбрать из них 100 пользователей\n",
    "4. Для каждого пользователя считать метрику близости между исполнителями, которых прослушал пользователь, и всеми остальными исполнителями\n",
    "5. Сортировать артистов по возрастанию среднего метрики близости от уже прослушанных исполнителей\n",
    "6. Считать среднее относительное место исполнителей, которых прослушал пользователь во время test периода. Меньше место - лучше результат модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Функция подсчета количества треков исполнителя для каждого пользователя/плейлиста/сессии\n",
    "def count_agg(event_data, track_data, second_var, agg_col, fun):\n",
    "    merged_data = event_data.merge(track_data, on = 'track_id')\n",
    "    user_artist_count = merged_data.groupby([second_var, 'artist_id']).agg({agg_col : fun}).rename(columns = {agg_col : 'stat'}).reset_index()\n",
    "    \n",
    "    return(user_artist_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Добавление индексов для исполнителя и второй переменной (пользователь, сессия, плейлист и т.д.)\n",
    "def add_idx(data, second_var):\n",
    "    indexes_user = pd.DataFrame({\n",
    "        '{}'.format(second_var) : data[second_var].unique(),\n",
    "        '{}_matrix'.format(second_var) : list(range(0, len(data[second_var].unique())))\n",
    "    }\n",
    "    )\n",
    "    indexes_artist = pd.DataFrame({\n",
    "        'artist_id' : data['artist_id'].unique(),\n",
    "        'artist_id_matrix' : list(range(0, len(data['artist_id'].unique())))\n",
    "    }\n",
    "    )\n",
    "    data = data.merge(indexes_user).merge(indexes_artist)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Разбиваем на train и test по времени и выбираем пользователей, для которых будем рекомендовать исполнителей\n",
    "def traintest_split(event_data, test_start = 1405000000, test_period = 5184000):\n",
    "    train_events = event_data[event_data['timestamp'] <= test_start]\n",
    "    test_events = event_data[(event_data['timestamp'] > test_start) & (event_data['timestamp'] < (test_start+test_period))]\n",
    "        \n",
    "    return (train_events, test_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Разбиваем на train и test по времени и выбираем пользователей, для которых будет рекомендовать исполнителей\n",
    "def select_users(event_data, test_start = 1405000000, test_period = 5184000, num_users = 100, seed = 599_000):\n",
    "    train_events = event_data[event_data['timestamp'] <= test_start]\n",
    "    train_events = count_agg(train_events, track_data, 'user_id', 'event_id', 'count')\n",
    "    \n",
    "    test_events = event_data[(event_data['timestamp'] > test_start) & (event_data['timestamp'] < (test_start+test_period))]\n",
    "    test_events = count_agg(test_events, track_data, 'user_id', 'event_id', 'count')\n",
    "    \n",
    "    train_users = train_events[train_events['stat'] > 5]['user_id'].values\n",
    "    test_users = test_events[train_events['stat'] > 5]['user_id'].values\n",
    "    \n",
    "    aval_users = np.intersect1d(train_users, test_users)\n",
    "    np.random.seed(seed)\n",
    "    sampled_users = np.random.choice(aval_users, num_users)\n",
    "    \n",
    "        \n",
    "    return(sampled_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Создание матрицы исполнители - пользователи/сессии/плейлисты и тд.\n",
    "def creating_matrix(data, col_data, value):\n",
    "    col = data[col_data].values\n",
    "    row = data['artist_id_matrix'].values\n",
    "    data = data[value].values\n",
    "    matrix = csr_matrix((data, (row, col)))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Выбрать исполнителей, похожих на исполнителей, которых пользователь уже слушал, на основе матрицы train_matrix\n",
    "def predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, metric, inverse = False, verbose = True):\n",
    "    global similarities\n",
    "    all_metrics = []\n",
    "    num_train_artists = []\n",
    "    num_test_artists = []\n",
    "    \n",
    "    for user in sampled_users: ## Для каждого пользователя\n",
    "        start = time.time()\n",
    "        \n",
    "        ## Выбираем информацию о прослушиваниях исполнителей для конкретного пользователя для тренировочного и тестового периодов\n",
    "        user_train_data = train_data[train_data['user_id'] == user]\n",
    "        user_train_artists = user_train_data['artist_id'].values\n",
    "        user_test_data = test_data[test_data['user_id'] == user]\n",
    "        user_test_artists = user_test_data['artist_id'].values\n",
    "        \n",
    "        ## Переводим id исполнителей в номера строк матрицы информации об исполнителях\n",
    "        user_train_artists = matrix_id[matrix_id['artist_id'].isin(user_train_artists)]['artist_id_matrix'].unique()\n",
    "        user_test_artists = matrix_id[matrix_id['artist_id'].isin(user_test_artists)]['artist_id_matrix'].unique()\n",
    "        \n",
    "        ## Создаем пустой векторр схожести исполнителей\n",
    "        user_similarity_matrix = np.empty(shape = (train_matrix.shape[0], 1))\n",
    "        \n",
    "        ## Для каждого исполнителя из списка исполнителей, которых прослушал пользователь во время train периода\n",
    "        for artist in user_train_artists:\n",
    "            \n",
    "            ## Считаем схожесть между исполнителем и всеми остальными исполнителями из матрицы информации об исполнителях\n",
    "            artist_similarity = pairwise_distances(train_matrix, train_matrix[artist, :], metric = metric)\n",
    "            \n",
    "            ## Развернуть ли метрику схожести или нет (например с евклидовой метрикой - больше расстояние, разворачиваем, значением метрики становится меньше)\n",
    "            if inverse == True:\n",
    "                artist_similarity = 1/(1+artist_similarity)\n",
    "            \n",
    "            ## Добавляем столбец схожестимежду исполнителем и всеми остальными исполнителями\n",
    "            user_similarity_matrix = np.concatenate((user_similarity_matrix, artist_similarity), axis = 1)\n",
    "        \n",
    "        ## Считаем среднюю схожесть между тренировочными исполнителями и всеми остальными\n",
    "        similarities = np.mean(user_similarity_matrix, axis = 1)\n",
    "        \n",
    "        ## Сортируем индексы строк по убыванию значения в этой строке в порядке возрастания (то есть от самых похожих к самым непохожим исполнителям)\n",
    "        similarities = np.argsort(similarities)  ### argsort по умолчанию сортирует в порядке возрастания \n",
    "        \n",
    "        ## Считаем средний индекс (то есть среднюю позицию в ранжированном списке) исполнителей из тестового периода, которых прослушал пользователь\n",
    "        positions = np.isin(similarities, user_test_artists)\n",
    "        positions = np.where(positions == True)\n",
    "        result = np.mean(positions[0])/len(similarities)\n",
    "        \n",
    "        ## Добавляем информацию о метрике и количестве исполнителей в тренировочном и тестовом датасете\n",
    "        all_metrics.append(result)\n",
    "        num_train_artists.append(len(user_train_artists))\n",
    "        num_test_artists.append(len(user_test_artists))  \n",
    "            \n",
    "        if verbose:\n",
    "            print('Metric: {}, Number of train artists: {},Number of test artists: {}, Train time: {}'.format(result, len(user_train_artists), len(user_test_artists), time.time()-start))\n",
    "    return(all_metrics, sampled_users, num_train_artists, num_test_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Добавить результаты в csv файл\n",
    "def add_results(all_metrics, sampled_users, num_train_artist, num_test_artists, model_name):\n",
    "    data = pd.DataFrame(np.array([all_metrics, sampled_users, num_train_artist, num_test_artists]).T, columns = pd.MultiIndex.from_product([[model_name], ['scores', 'user', 'num_train_artist', 'num_test_artists']]))\n",
    "    if path.exists('results.csv'):\n",
    "        results_loaded = pd.read_csv('results.csv', header=[0,1])\n",
    "        data = pd.concat([results_loaded, data], axis = 'columns')\n",
    "        \n",
    "    data.to_csv('results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В бейзлайн модели будем сравнивать исполнителей на основе количества их треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "track_data = pd.read_csv('tracks_modified.csv')\n",
    "event_data = pd.read_csv('events_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "similarities = track_data['artist_id'].value_counts().sort_values(ascending = False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_events, test_events = traintest_split(event_data)\n",
    "test_events = test_events.merge(track_data, on = 'track_id')\n",
    "sampled_users = select_users(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for user in sampled_users:\n",
    "    user_test_data = test_events[test_events['user_id'] == user]\n",
    "    user_test_artists = user_test_data['artist_id'].unique()\n",
    "    \n",
    "    positions = np.isin(similarities, user_test_artists)\n",
    "    positions = np.where(positions == True)\n",
    "    result = np.mean(positions[0])/len(similarities)\n",
    "    all_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Model result:' , np.mean(all_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'baseline_results' : all_results}).to_csv('baseline_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Таким образом, результат baseline модели - 0.179, то есть в среднем, прослушанные во время тестового периода исполнители находятся в топ 17% ранжированного списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Advanced models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "В advanced моделях будем использовать информацию о прослушиваниях треков артистов из различных датасетов (прослушивания, плейлисты, сессии)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events_modified.csv')\n",
    "track_data = pd.read_csv('tracks_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_events, test_events = traintest_split(event_data)\n",
    "sampled_users = select_users(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = count_agg(train_events, track_data, 'user_id', 'playtime', 'sum') \n",
    "train_data = add_idx(train_data, 'user_id')\n",
    "\n",
    "test_data = count_agg(test_events, track_data, 'user_id', 'playtime', 'sum')\n",
    "test_data = add_idx(test_data, 'user_id')\n",
    "\n",
    "train_matrix = creating_matrix(train_data, 'user_id_matrix', 'stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix_id = train_data[['artist_id', 'artist_id_matrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train_events, test_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in ['cosine', 'manhattan', 'euclidean']:\n",
    "    print(metric)\n",
    "    if metric != 'cosine':\n",
    "        print('Not cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, metric, inverse = True)\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'events_mod_tracks_mod_total_playtime_{}'.format(metric))\n",
    "    elif metric == 'cosine':\n",
    "        print('Actually cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, 'cosine')\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'events_mod_tracks_mod_total_playtime_cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events_modified.csv')\n",
    "track_data = pd.read_csv('tracks_modified.csv')\n",
    "session_data = pd.read_csv('sessions_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_events, test_events = traintest_split(event_data)\n",
    "sampled_users = select_users(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = count_agg(train_events, track_data, 'user_id', 'playtime', 'sum')\n",
    "train_data = add_idx(train_data, 'user_id')\n",
    "\n",
    "test_data = count_agg(test_events, track_data, 'user_id', 'playtime', 'sum')\n",
    "test_data = add_idx(test_data, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_session, test_session = traintest_split(session_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_session = count_agg(train_session, track_data, 'session_id', 'playtime', 'count')\n",
    "train_session = add_idx(train_session, 'session_id')\n",
    "train_matrix = creating_matrix(train_session, 'session_id_matrix', 'stat')\n",
    "matrix_id = train_session[['artist_id', 'artist_id_matrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train_events, test_events, train_session, test_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in ['cosine', 'manhattan', 'euclidean']:\n",
    "    print(metric)\n",
    "    if metric != 'cosine':\n",
    "        print('Not cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, metric, inverse = True)\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'sessions_mod_tracks_mod_total_playtime_{}'.format(metric))\n",
    "    elif metric == 'cosine':\n",
    "        print('Actually cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, 'cosine')\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'sessions_mod_tracks_mod_total_playtime_cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events_modified.csv')\n",
    "track_data = pd.read_csv('tracks_modified.csv')\n",
    "playlist_data = pd.read_csv('playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_events, test_events = traintest_split(event_data)\n",
    "sampled_users = select_users(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = count_agg(train_events, track_data, 'user_id', 'event_id', 'count')\n",
    "train_data = add_idx(train_data, 'user_id')\n",
    "\n",
    "test_data = count_agg(test_events, track_data, 'user_id', 'event_id', 'count')\n",
    "test_data = add_idx(test_data, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_playlist, test_playlist= traintest_split(playlist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_playlist = count_agg(train_playlist, track_data, 'playlist_id', 'user_id', 'count')\n",
    "train_playlist = add_idx(train_playlist, 'playlist_id')\n",
    "train_matrix = creating_matrix(train_playlist, 'playlist_id_matrix', 'stat')\n",
    "matrix_id = train_playlist[['artist_id', 'artist_id_matrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train_events, test_events, train_playlist, test_playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for metric in ['cosine', 'manhattan', 'euclidean']:\n",
    "    print(metric)\n",
    "    if metric != 'cosine':\n",
    "        print('Not cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, metric, inverse = True)\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'playlists_tracks_mod_count_{}'.format(metric))\n",
    "    elif metric == 'cosine':\n",
    "        print('Actually cosine')\n",
    "        all_metrics, sampled_users, num_train_artists, num_test_artists = predict_similar(sampled_users, train_data, test_data, train_matrix, matrix_id, 'cosine')\n",
    "        add_results(all_metrics, sampled_users, num_train_artists, num_test_artists, 'playlists_tracks_mod_count_cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Общие выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('results_full.csv', header = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results[['events_mod_tracks_mod_total_playtime_cosine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_results = results.xs('scores', level=1, drop_level=False, axis = 1).mean().sort_values().droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (10, 10))\n",
    "_ = sns.barplot(y = mean_results.index, x = mean_results.values)\n",
    "_ = plt.xticks(rotation='45')\n",
    "_ = plt.title('Среднее значение метрики для моделей (меньше - лучше)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Как видно, на данной задаче лучше всего себя показала модель, рассчитывающая схожесть с помощью косинусного расстояния на основе информации о прослушиваниях треков различных исполнителей различными пользователями\n",
    "\n",
    "В целом на большинстве векторных представлений лучший результат показывала метрика расстояния - косинусная близость. Это связано с тем, что в данной задаче скорее важны соотношения между количеством треков в плейлисте/сессии/у пользователя разных исполнителей, а не их абсолютное значение. Косинусное расстояние между, например, точкой (1, 1) и (10, 10) равно нулю, в то время как евклидова метрика и расстояние манхэттена в данном случае отличны от нуля.\n",
    "\n",
    "Метрики близости, рассчитанные на основе данных о прослушиваниях пользователями треков исполнителей показала лучшие результаты, потому что данное векторное представление наилучшим образом предпочтения пользователей.\n",
    "\n",
    "Важное дополнение: на одном из этапов работы результаты работы моделей отценивались как среднее место прослушанных треков в ранжированном списке, однако это приводило к неправильной трактовке резултатов: модель основанная на данных о плейлистах давала слишком хорошие результаты, эжто происходило потому, что в данных о плейлистах содержится информация о треках всего 33705 уникальных исполнителей, в то время как в данных о сессиях и прослушиваниях содержатся треки 401415 и 347523 исполнителей соотвественно. Скорее всего исполнители, треки которых есть в плейлистах, в целом являются более актуальными и популярными, что также сказывалось на результатах модели, однако эти результаты не показывали реальной точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events_modified.csv')\n",
    "track_data = pd.read_csv('tracks_modified.csv')\n",
    "session_data = pd.read_csv('sessions_modified.csv')\n",
    "playlist_data = pd.read_csv('playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Количество уникальных исполнителей в плейлистах: ', len(pd.merge(playlist_data, track_data, on = 'track_id', how = 'inner')['artist_id'].unique()))\n",
    "print('Количество уникальных исполнителей в списке прослушиваний: ', len(pd.merge(event_data, track_data, on = 'track_id', how = 'inner')['artist_id'].unique()))\n",
    "print('Количество уникальных исполнителей в сессиях: ', len(pd.merge(session_data, track_data, on = 'track_id', how = 'inner')['artist_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Проверка статистической значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим статистическую значимость полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = results['events_mod_tracks_mod_mean_playtime_cosine']['scores'].values\n",
    "plt.figure(figsize = (10,10))\n",
    "_ = sns.distplot(data, bins = 30)\n",
    "_ = plt.axvline(np.nanmean(data), color = 'red', label = 'mean = {}'.format(round(np.nanmean(data), 4)))\n",
    "_ = plt.axvline(np.nanmedian(data), color = 'green', label = 'median = {}'.format(round(np.nanmedian(data), 4)))\n",
    "_ = plt.legend(loc=\"upper left\")\n",
    "_ = plt.title('Распределение результатов для модели events_mod_tracks_mod_mean_playtime_cosine\\n variance = {}'.format(np.nanstd(data)))\n",
    "\n",
    "\n",
    "data = results['events_mod_tracks_mod_count_cosine']['scores'].values\n",
    "plt.figure(figsize = (10,10))\n",
    "_ = sns.distplot(data, bins = 30)\n",
    "_ = plt.axvline(np.nanmean(data), color = 'red', label = 'mean = {}'.format(round(np.nanmean(data), 4)))\n",
    "_ = plt.axvline(np.nanmedian(data), color = 'green', label = 'median = {}'.format(round(np.nanmedian(data), 4)))\n",
    "_ = plt.legend(loc=\"upper left\")\n",
    "_ = plt.title('Распределение результатов для модели events_mod_tracks_mod_count_cosine\\n variance = {}'.format(np.nanstd(data)))\n",
    "\n",
    "\n",
    "data = results['events_mod_tracks_mod_total_playtime_cosine']['scores'].values\n",
    "plt.figure(figsize = (10,10))\n",
    "_ = sns.distplot(data, bins = 30)\n",
    "_ = plt.axvline(np.nanmean(data), color = 'red', label = 'mean = {}'.format(round(np.nanmean(data), 4)))\n",
    "_ = plt.axvline(np.nanmedian(data), color = 'green', label = 'median = {}'.format(round(np.nanmedian(data), 4)))\n",
    "_ = plt.legend(loc=\"upper left\")\n",
    "_ = plt.title('Распределение результатов для модели events_mod_tracks_mod_total_playtime_cosine\\n variance = {}'.format(np.nanstd(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Распределения не являются нормальными, так что при оценке статистчиеской значимости будем использовать непараметррические тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Проверим, являются ли различия в результатах моделей статистически значимыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_scores = results[['events_mod_tracks_mod_mean_playtime_cosine', 'events_mod_tracks_mod_count_cosine', 'events_mod_tracks_mod_total_playtime_cosine']].xs('scores', level=1, drop_level=False, axis = 1).droplevel(1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_value_frame = pd.DataFrame(index = results_scores.columns, columns = results_scores.columns, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column1 in results_scores:\n",
    "    for column2 in results_scores:\n",
    "        p_value = stats.mannwhitneyu(results_scores[column1], \n",
    "                                     results_scores[column2], \n",
    "                                     alternative = 'two-sided')\n",
    "        p_value_frame.loc[column1, column2] = p_value[1]\n",
    "        p_value_frame.loc[column2, column1] = p_value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize = (6, 6))\n",
    "_ = sns.heatmap(p_value_frame, annot=True, cmap='viridis')\n",
    "_ = plt.xticks(rotation = 45)\n",
    "_ = plt.title('P-value от теста манна уитни на разность между средними выборок')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Таким образом, модели на основе данных о прослушиваниях треков с использованием косинусной метрики близости дают статистически незначимо различные результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Также проверим статистическую значимость различия результатов baseline модели и лучшей advanced модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "baseline_results = pd.read_csv('baseline_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plt.title('Распределение среднего результата baseline модели')\n",
    "_ = sns.distplot(baseline_results['baseline_results'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(baseline_results['baseline_results'].values,\n",
    "                   results_scores['events_mod_tracks_mod_mean_playtime_cosine'].values,\n",
    "                   alternative = 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "P-value = 0.03, таким образом различие в средних значениях резулльтатов baseline и advanced моделей является статистически значимым, т.к. вероятность получить более крайние значения статистики = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Итого, лучшая модель - подсчет схожести исполнителей на основе данных о прослушанных пользователями исполнителей с помощью косинусной близости. При этом средний результат составил ~0.16, что на 0.34 лучше, чем у модели, рандомно ранжирующей исполнителей, и на ~0.02 лучше, чем у baseline модели. Также важное отличие от baseline модели заключается в том, что baseline модель хорошо ранжирует исполнителей, но показывает такие хорошие результаты лишь потому, что у самых популярных исполнителей (то есть тех, которых слушает множество пользователей) много треков, соотвественно они оказываются близки в верху ранжируемого списка, одна такое ранжирование имеет мало отношения к схожести между исполнителями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Результаты: кратко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Лучшая модель - подсчет схожести исполнителей на основе данных о прослушанных пользователями исполнителей с помощью косинусной близости. При этом средний результат составил ~0.16.\n",
    "Векторное представление: вектор числа прослушиваний/среднего вемени прослушивания/общего вемени прослушивания (результаты этих моделей рразличаются статистически незначимо) пользователями треков каждого отдельного исполнителя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Примеры похожих исполнителей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv('events_modified.csv')\n",
    "track_data = pd.read_csv('tracks_modified.csv')\n",
    "person_data = pd.read_csv('persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = count_agg(event_data, track_data, 'user_id', 'event_id', 'count')\n",
    "all_data = add_idx(all_data, 'user_id')\n",
    "all_matrix = creating_matrix(all_data, 'user_id_matrix', 'stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Выберем 3 исполнителей с id: 443804, 55302, 356929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(person_data[person_data['person_id'] == 443804]['artist_name'].values[0])\n",
    "print(person_data[person_data['person_id'] == 55302]['artist_name'].values[0])\n",
    "print(person_data[person_data['person_id'] == 356929]['artist_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exmpl_artists = [11893, 15230, 24590]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artist_similarity1 = pairwise_distances(all_matrix, all_matrix[exmpl_artists[0], :], metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_1 = np.argsort(np.concatenate(artist_similarity1))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_1 = all_data[all_data['artist_id_matrix'].isin(top_20_1)]['artist_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Таким образом, самые похожие исполнители на исполнителя Irma and The Fascinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data[person_data['person_id'].isin(top_20_1)]['artist_name'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artist_similarity2 = pairwise_distances(all_matrix, all_matrix[exmpl_artists[1], :], metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_2 = np.argsort(np.concatenate(artist_similarity2))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_2 = all_data[all_data['artist_id_matrix'].isin(top_20_2)]['artist_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Самые похожие исполнители на исполнителя Bongripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data[person_data['person_id'].isin(top_20_2)]['artist_name'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artist_similarity3 = pairwise_distances(all_matrix, all_matrix[exmpl_artists[2], :], metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_3 = np.argsort(np.concatenate(artist_similarity3))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_20_3 = all_data[all_data['artist_id_matrix'].isin(top_20_3)]['artist_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Самые похожие исполнители на исполнителя The Funky Lowlives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "person_data[person_data['person_id'].isin(top_20_3)]['artist_name'].reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
